# Complete Workflow Execution Map

**Date**: July 26, 2025  
**Status**: âœ… Complete  
**Purpose**: Visual map of complete file/function call chain for the entire typing clients ingestion pipeline

## Overview

This document provides a comprehensive ASCII visual representation of the complete workflow execution flow, showing every file and function called when running the pipeline from start to finish.

---

## ğŸ¯ COMPLETE WORKFLOW EXECUTION FLOW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           TYPING CLIENTS INGESTION PIPELINE                      â”‚
â”‚                         Complete File/Function Call Chain                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ ENTRY POINT: python simple_workflow.py [--basic|--text] [options]
â”‚
â”œâ”€â”€ simple_workflow.py::main()
â”‚   â”œâ”€â”€ parse_arguments() â†’ argparse configuration
â”‚   â”œâ”€â”€ config loading from utils/config.py::get_config()
â”‚   â”‚   â””â”€â”€ config/config.yaml â† Configuration loaded
â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚                              STEP 1: DOWNLOAD SHEET                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   â”œâ”€â”€ step1_download_sheet()
â”‚   â”‚   â”œâ”€â”€ utils/http_pool.py::get() â†’ HTTP request to Google Sheets
â”‚   â”‚   â”‚   â””â”€â”€ ğŸŒ https://docs.google.com/spreadsheets/d/[SHEET_ID]/edit
â”‚   â”‚   â””â”€â”€ sheet.html â† Raw HTML cached locally
â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚                        STEP 2: EXTRACT PEOPLE & DOCS                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   â”œâ”€â”€ step2_extract_people_and_docs(html_content)
â”‚   â”‚   â”œâ”€â”€ BeautifulSoup â†’ Parse HTML table structure
â”‚   â”‚   â”œâ”€â”€ utils/extract_links.py::extract_actual_url() â†’ Clean Google redirect URLs
â”‚   â”‚   â”œâ”€â”€ Row extraction: [row_id, name, email, type, doc_link]
â”‚   â”‚   â”œâ”€â”€ Link categorization:
â”‚   â”‚   â”‚   â”œâ”€â”€ Google Docs: docs.google.com/document/[DOC_ID]
â”‚   â”‚   â”‚   â”œâ”€â”€ Direct YouTube: youtube.com/watch?v=[VIDEO_ID]
â”‚   â”‚   â”‚   â””â”€â”€ Direct Drive: drive.google.com/file/d/[FILE_ID]
â”‚   â”‚   â””â”€â”€ Returns: all_people[], people_with_docs[]
â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚                         PROCESSING MODE SELECTION                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   â”‚
â”‚   â”œâ”€â”€â”€ BASIC MODE (--basic flag)
â”‚   â”‚    â””â”€â”€ utils/csv_manager.py::create_record(mode='basic')
â”‚   â”‚        â””â”€â”€ Minimal CSV: [row_id, name, email, type, link]
â”‚   â”‚
â”‚   â”œâ”€â”€â”€ TEXT MODE (--text flag)
â”‚   â”‚    â”œâ”€â”€ Batch processing with progress tracking
â”‚   â”‚    â”œâ”€â”€ utils/extract_links.py::extract_text_with_retry()
â”‚   â”‚    â”‚   â”œâ”€â”€ Selenium WebDriver initialization
â”‚   â”‚    â”‚   â”œâ”€â”€ utils/patterns.py::get_selenium_driver()
â”‚   â”‚    â”‚   â”œâ”€â”€ Google Doc text extraction
â”‚   â”‚    â”‚   â””â”€â”€ Error handling with retry logic
â”‚   â”‚    â”œâ”€â”€ Progress state management
â”‚   â”‚    â”‚   â”œâ”€â”€ utils/config.py::load_json_state()
â”‚   â”‚    â”‚   â””â”€â”€ extraction_progress.json â† Progress tracking
â”‚   â”‚    â””â”€â”€ utils/csv_manager.py::create_record(mode='text')
â”‚   â”‚
â”‚   â””â”€â”€â”€ FULL MODE (default)
â”‚        â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚                        STEP 3: SCRAPE DOC CONTENTS                     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚        â”œâ”€â”€ step3_scrape_doc_contents(doc_url)
â”‚        â”‚   â”œâ”€â”€ Google Doc Detection: "docs.google.com/document" in url
â”‚        â”‚   â”œâ”€â”€ utils/extract_links.py::extract_google_doc_text()
â”‚        â”‚   â”‚   â”œâ”€â”€ utils/patterns.py::get_selenium_driver()
â”‚        â”‚   â”‚   â”œâ”€â”€ Selenium navigation to document
â”‚        â”‚   â”‚   â”œâ”€â”€ Wait for content loading
â”‚        â”‚   â”‚   â”œâ”€â”€ Text extraction from DOM
â”‚        â”‚   â”‚   â””â”€â”€ utils/patterns.py::cleanup_selenium_driver()
â”‚        â”‚   â”œâ”€â”€ utils/http_pool.py::get() â†’ HTML content extraction
â”‚        â”‚   â””â”€â”€ Returns: (html_content, doc_text)
â”‚        â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚                         STEP 4: EXTRACT LINKS                          â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚        â”œâ”€â”€ step4_extract_links(doc_content, doc_text)
â”‚        â”‚   â”œâ”€â”€ Content preparation & Unicode decoding
â”‚        â”‚   â”œâ”€â”€ utils/patterns.py::PatternRegistry patterns:
â”‚        â”‚   â”‚   â”œâ”€â”€ YOUTUBE_VIDEO_FULL â†’ youtube.com/watch?v=[VIDEO_ID]
â”‚        â”‚   â”‚   â”œâ”€â”€ YOUTUBE_SHORT_FULL â†’ youtu.be/[VIDEO_ID]
â”‚        â”‚   â”‚   â”œâ”€â”€ YOUTUBE_PLAYLIST_FULL â†’ youtube.com/playlist?list=[LIST_ID]
â”‚        â”‚   â”‚   â”œâ”€â”€ DRIVE_FILE_FULL â†’ drive.google.com/file/d/[FILE_ID]
â”‚        â”‚   â”‚   â”œâ”€â”€ DRIVE_OPEN_FULL â†’ drive.google.com/open?id=[FILE_ID]
â”‚        â”‚   â”‚   â”œâ”€â”€ DRIVE_FOLDER_FULL â†’ drive.google.com/drive/folders/[FOLDER_ID]
â”‚        â”‚   â”‚   â””â”€â”€ HTTP_URL â†’ All http(s) links
â”‚        â”‚   â”œâ”€â”€ filter_meaningful_links() â†’ Remove infrastructure noise
â”‚        â”‚   â”‚   â”œâ”€â”€ Noise filtering: googleapis.com, gstatic.com, schema.org
â”‚        â”‚   â”‚   â”œâ”€â”€ Content validation: actual video/file IDs required
â”‚        â”‚   â”‚   â””â”€â”€ URL normalization: standardized formats
â”‚        â”‚   â””â”€â”€ Returns: {youtube: [], drive_files: [], drive_folders: [], all_links: []}
â”‚        â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚                      STEP 5: PROCESS EXTRACTED DATA                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚        â”œâ”€â”€ step5_process_extracted_data(person, links, doc_text)
â”‚        â”‚   â”œâ”€â”€ utils/config.py::ensure_directory() â†’ Create output directories
â”‚        â”‚   â”œâ”€â”€ filter_meaningful_links() â†’ Secondary filtering
â”‚        â”‚   â”œâ”€â”€ utils/csv_manager.py::create_record(mode='full')
â”‚        â”‚   â”‚   â”œâ”€â”€ Field mapping: row_id, name, email, type, link
â”‚        â”‚   â”‚   â”œâ”€â”€ Links processing: youtube_playlist, google_drive JSON
â”‚        â”‚   â”‚   â”œâ”€â”€ Metadata: document_text, total_links, processing_info
â”‚        â”‚   â”‚   â”œâ”€â”€ S3 integration: file_uuids, s3_paths JSON columns
â”‚        â”‚   â”‚   â””â”€â”€ Timestamps: extracted_at, updated_at
â”‚        â”‚   â””â”€â”€ Returns: complete_record_dict
â”‚        â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚                           STEP 6: MAP DATA TO CSV                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚        â””â”€â”€ step6_map_data(processed_records, basic_mode, text_mode, output_file)
â”‚            â”œâ”€â”€ Column configuration from utils/config.py
â”‚            â”‚   â”œâ”€â”€ Basic: ['row_id', 'name', 'email', 'type', 'link']
â”‚            â”‚   â”œâ”€â”€ Text: Basic + ['document_text', 'processing_info']
â”‚            â”‚   â””â”€â”€ Full: All 23 columns including S3 UUID mappings
â”‚            â”œâ”€â”€ Record filtering & validation
â”‚            â”œâ”€â”€ pandas.DataFrame creation
â”‚            â”œâ”€â”€ utils/csv_manager.py::safe_csv_write()
â”‚            â”‚   â”œâ”€â”€ utils/file_lock.py::file_lock() â†’ Atomic write protection
â”‚            â”‚   â”œâ”€â”€ CSV backup creation with timestamp
â”‚            â”‚   â”œâ”€â”€ Data validation & sanitization
â”‚            â”‚   â”œâ”€â”€ utils/csv_s3_versioning.py â†’ S3 versioning support
â”‚            â”‚   â””â”€â”€ outputs/output.csv â† Final CSV output
â”‚            â””â”€â”€ Statistics & summary reporting

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              S3 STREAMING PIPELINE                              â”‚
â”‚                        (When media files need processing)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”„ STREAMING EXECUTION: python core/stream_folder_contents_direct.py
â”‚
â”œâ”€â”€ core/stream_folder_contents_direct.py::stream_drive_folders_direct()
â”‚   â”œâ”€â”€ utils/s3_manager.py::UnifiedS3Manager()
â”‚   â”‚   â”œâ”€â”€ S3Config loading: bucket, credentials, upload mode
â”‚   â”‚   â””â”€â”€ boto3 S3 client initialization
â”‚   â”œâ”€â”€ utils/download_drive.py::list_folder_files()
â”‚   â”‚   â”œâ”€â”€ Google Drive API authentication
â”‚   â”‚   â”œâ”€â”€ Folder content listing: file IDs, names, sizes
â”‚   â”‚   â””â”€â”€ utils/download_drive.py::extract_file_id()
â”‚   â”œâ”€â”€ For each file in folder:
â”‚   â”‚   â”œâ”€â”€ UUID generation: str(uuid.uuid4())
â”‚   â”‚   â”œâ”€â”€ S3 key creation: f"files/{uuid}{extension}"
â”‚   â”‚   â”œâ”€â”€ utils/s3_manager.py::stream_drive_to_s3()
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸŒ Google Drive download URL construction
â”‚   â”‚   â”‚   â”œâ”€â”€ requests.get(stream=True) â†’ Streaming download
â”‚   â”‚   â”‚   â”œâ”€â”€ BytesIO buffering â†’ In-memory processing
â”‚   â”‚   â”‚   â”œâ”€â”€ s3_client.upload_fileobj() â†’ Direct S3 upload
â”‚   â”‚   â”‚   â””â”€â”€ âœ… Zero local storage usage
â”‚   â”‚   â”œâ”€â”€ CSV updating via utils/csv_manager.py
â”‚   â”‚   â”‚   â”œâ”€â”€ JSON field updates: file_uuids, s3_paths
â”‚   â”‚   â”‚   â”œâ”€â”€ Metadata preservation: original_filename, source
â”‚   â”‚   â”‚   â””â”€â”€ UUID â†’ S3 path mapping storage
â”‚   â”‚   â””â”€â”€ Progress tracking & error handling
â”‚   â””â”€â”€ Returns: complete_s3_upload_report

ğŸ”§ EXTENSION FIXING: python core/fix_s3_extensions.py
â”‚
â”œâ”€â”€ core/fix_s3_extensions.py::fix_s3_file_extensions()
â”‚   â”œâ”€â”€ File mapping definition: UUID â†’ {filename, extension, content_type}
â”‚   â”œâ”€â”€ For each UUID mapping:
â”‚   â”‚   â”œâ”€â”€ boto3.s3_client.head_object() â†’ Check file existence
â”‚   â”‚   â”œâ”€â”€ boto3.s3_client.copy_object() â†’ Copy with new extension
â”‚   â”‚   â”‚   â”œâ”€â”€ MetadataDirective='REPLACE'
â”‚   â”‚   â”‚   â”œâ”€â”€ ContentType update: video/mp4, application/docx
â”‚   â”‚   â”‚   â””â”€â”€ Metadata preservation: original_filename
â”‚   â”‚   â”œâ”€â”€ boto3.s3_client.delete_object() â†’ Remove old .bin file
â”‚   â”‚   â””â”€â”€ CSV path updates: JSON field corrections
â”‚   â””â”€â”€ Returns: extension_fix_summary

ğŸ”„ METADATA PROCESSING: python core/process_pending_metadata_downloads.py
â”‚
â”œâ”€â”€ core/process_pending_metadata_downloads.py::main()
â”‚   â”œâ”€â”€ utils/csv_manager.py::CSVManager.read()
â”‚   â”œâ”€â”€ Metadata filtering: has_metadata=True, has_media=False
â”‚   â”œâ”€â”€ For each pending person:
â”‚   â”‚   â”œâ”€â”€ utils/row_context.py::RowContext creation
â”‚   â”‚   â”œâ”€â”€ YouTube processing:
â”‚   â”‚   â”‚   â”œâ”€â”€ _download_youtube_playlist_direct()
â”‚   â”‚   â”‚   â”œâ”€â”€ yt-dlp command construction
â”‚   â”‚   â”‚   â”œâ”€â”€ subprocess.run() â†’ Direct YouTube download
â”‚   â”‚   â”‚   â””â”€â”€ Local â†’ S3 upload via utils/s3_manager.py
â”‚   â”‚   â”œâ”€â”€ Google Drive processing:
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/download_drive.py::download_drive_file()
â”‚   â”‚   â”‚   â”œâ”€â”€ Direct streaming via utils/s3_manager.py::stream_drive_to_s3()
â”‚   â”‚   â”‚   â””â”€â”€ UUID generation & CSV mapping
â”‚   â”‚   â””â”€â”€ Progress tracking: metadata_download_progress.json
â”‚   â””â”€â”€ Returns: metadata_processing_report

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CRITICAL UTILITIES                                 â”‚
â”‚                           (Supporting Infrastructure)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ utils/config.py
â”œâ”€â”€ get_config() â†’ config/config.yaml loading
â”œâ”€â”€ ensure_directory() â†’ Path creation with permissions
â”œâ”€â”€ ensure_parent_dir() â†’ Parent directory validation
â”œâ”€â”€ load_json_state() â†’ JSON state file loading
â”œâ”€â”€ save_json_state() â†’ JSON state file saving
â””â”€â”€ format_error_message() â†’ Standardized error formatting

ğŸ“ utils/patterns.py
â”œâ”€â”€ PatternRegistry class â†’ Centralized regex patterns
â”œâ”€â”€ extract_youtube_id() â†’ Video ID extraction
â”œâ”€â”€ extract_drive_id() â†’ Drive file ID extraction
â”œâ”€â”€ clean_url() â†’ URL sanitization
â”œâ”€â”€ normalize_whitespace() â†’ Text normalization
â”œâ”€â”€ get_selenium_driver() â†’ WebDriver with configuration
â””â”€â”€ cleanup_selenium_driver() â†’ Resource cleanup

ğŸ“ utils/error_handling.py
â”œâ”€â”€ with_standard_error_handling() â†’ Decorator for error wrapping
â”œâ”€â”€ create_error_context() â†’ Context information generation
â”œâ”€â”€ handle_download_error() â†’ Download-specific error handling
â”œâ”€â”€ handle_extraction_error() â†’ Text extraction error handling
â””â”€â”€ format_error_details() â†’ Detailed error formatting

ğŸ“ utils/retry_utils.py
â”œâ”€â”€ retry_with_backoff() â†’ Exponential backoff retry logic
â”œâ”€â”€ calculate_delay() â†’ Dynamic delay calculation
â”œâ”€â”€ should_retry() â†’ Retry condition evaluation
â””â”€â”€ retry_state_tracking() â†’ Attempt counting & logging

ğŸ“ utils/http_pool.py
â”œâ”€â”€ get() â†’ Centralized HTTP requests with pooling
â”œâ”€â”€ connection_pooling() â†’ urllib3 PoolManager
â”œâ”€â”€ request_retry_logic() â†’ Built-in retry mechanisms
â””â”€â”€ response_validation() â†’ Status code & content validation

ğŸ“ utils/logging_config.py
â”œâ”€â”€ get_logger() â†’ Module-specific logger creation
â”œâ”€â”€ setup_logging() â†’ Global logging configuration
â”œâ”€â”€ print_section_header() â†’ Formatted section output
â””â”€â”€ log_performance_metrics() â†’ Execution timing

ğŸ“ utils/file_lock.py
â”œâ”€â”€ file_lock() â†’ Cross-process file locking
â”œâ”€â”€ FileLock class â†’ Context manager implementation
â”œâ”€â”€ lock_acquisition() â†’ Timeout & retry logic
â””â”€â”€ lock_cleanup() â†’ Resource cleanup on exit

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DATA FLOW SUMMARY                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŒ INPUT SOURCES:
â”œâ”€â”€ Google Sheets: https://docs.google.com/spreadsheets/d/[SHEET_ID]
â”œâ”€â”€ Google Docs: https://docs.google.com/document/d/[DOC_ID]
â”œâ”€â”€ YouTube Videos: https://www.youtube.com/watch?v=[VIDEO_ID]
â”œâ”€â”€ YouTube Playlists: https://www.youtube.com/playlist?list=[LIST_ID]
â”œâ”€â”€ Google Drive Files: https://drive.google.com/file/d/[FILE_ID]
â””â”€â”€ Google Drive Folders: https://drive.google.com/drive/folders/[FOLDER_ID]

ğŸ“Š PROCESSING STAGES:
1. Sheet Download â†’ Raw HTML caching
2. HTML Parsing â†’ People & document extraction
3. Document Scraping â†’ Content & text extraction
4. Link Extraction â†’ Media URL discovery
5. Data Processing â†’ Record standardization
6. CSV Mapping â†’ Structured output generation
7. S3 Streaming â†’ Direct cloud storage (when needed)
8. Extension Fixing â†’ Proper media types (when needed)
9. Metadata Processing â†’ Missing media recovery (when needed)

ğŸ’¾ OUTPUT DESTINATIONS:
â”œâ”€â”€ outputs/output.csv â†’ Main structured dataset
â”œâ”€â”€ s3://typing-clients-uuid-system/files/[UUID] â†’ Media files
â”œâ”€â”€ data/sheet.html â†’ Cached Google Sheet
â”œâ”€â”€ data/extraction_progress.json â†’ Progress tracking
â”œâ”€â”€ logs/runs/[TIMESTAMP]/ â†’ Execution logs
â””â”€â”€ Various backup & versioning files

ğŸ”— KEY INTEGRATIONS:
â”œâ”€â”€ Selenium WebDriver â†’ Google Docs text extraction
â”œâ”€â”€ BeautifulSoup â†’ HTML parsing & link extraction
â”œâ”€â”€ pandas â†’ CSV data manipulation
â”œâ”€â”€ boto3 â†’ S3 cloud storage operations
â”œâ”€â”€ requests â†’ HTTP communications
â”œâ”€â”€ yt-dlp â†’ YouTube content downloading
â””â”€â”€ Google Drive API â†’ Drive file operations

âš¡ PERFORMANCE OPTIMIZATIONS:
â”œâ”€â”€ HTTP connection pooling â†’ Reduced latency
â”œâ”€â”€ Direct streaming â†’ Zero local storage
â”œâ”€â”€ Atomic file operations â†’ Data integrity
â”œâ”€â”€ Progress state management â†’ Resumable operations
â”œâ”€â”€ Retry logic with backoff â†’ Reliability
â”œâ”€â”€ Meaningful link filtering â†’ Noise reduction
â””â”€â”€ UUID-based file organization â†’ Scalable storage

ğŸ›¡ï¸ SECURITY & RELIABILITY:
â”œâ”€â”€ File locking â†’ Concurrent access protection
â”œâ”€â”€ CSV versioning â†’ Data loss prevention
â”œâ”€â”€ Error context preservation â†’ Debugging support
â”œâ”€â”€ Sanitization â†’ Data integrity
â”œâ”€â”€ UUID file names â†’ Non-enumerable security
â””â”€â”€ Backup strategies â†’ Recovery capabilities
```

---

## ğŸ¯ EXECUTION MODES

### **Basic Mode** (`--basic`)
- **Purpose**: Extract only essential person data
- **Files Called**: `simple_workflow.py` â†’ `utils/csv_manager.py`
- **Output**: 5-column CSV (row_id, name, email, type, link)
- **Performance**: Fastest execution, no document processing

### **Text Mode** (`--text`)
- **Purpose**: Extract document text for analysis
- **Files Called**: All basic + `utils/extract_links.py` + Selenium
- **Output**: Basic columns + document_text + processing_info
- **Performance**: Medium speed, batch processing with progress tracking

### **Full Mode** (default)
- **Purpose**: Complete pipeline with media link extraction
- **Files Called**: All components in the workflow
- **Output**: Complete 23-column CSV with S3 UUID mappings
- **Performance**: Comprehensive processing, all features enabled

---

## ğŸ”„ STREAMING PIPELINE ACTIVATION

The streaming components activate when:

1. **Missing Media Detected**: `process_pending_metadata_downloads.py`
2. **Google Drive Folders**: `stream_folder_contents_direct.py`
3. **Extension Issues**: `fix_s3_extensions.py`

These operate independently but integrate with the main CSV via UUID mappings.

---

## ğŸ“‹ FILE DEPENDENCY MATRIX

| Component | Dependencies | Purpose |
|-----------|-------------|---------|
| `simple_workflow.py` | config, csv_manager, extract_links, patterns, http_pool | Main 6-step pipeline |
| `utils/csv_manager.py` | file_lock, sanitization, config, row_context, error_handling | CSV operations & S3 integration |
| `utils/extract_links.py` | http_pool, config, logging_config, patterns, error_handling | Document scraping & link extraction |
| `utils/s3_manager.py` | boto3, config, logging_config | S3 streaming operations |
| `utils/patterns.py` | selenium, logging_config | Regex patterns & WebDriver management |
| `core/stream_folder_contents_direct.py` | s3_manager, download_drive, logging_config | Direct Driveâ†’S3 streaming |
| `core/process_pending_metadata_downloads.py` | s3_manager, downloader, csv_manager, row_context | Metadata processing |
| `core/fix_s3_extensions.py` | boto3, pandas | Extension & content type correction |

---

## ğŸš€ EXECUTION EXAMPLES

### **Standard Full Pipeline**
```bash
python simple_workflow.py
# Calls: All 6 steps + full CSV generation
# Output: outputs/output.csv with complete data
```

### **Basic Data Extraction Only**
```bash
python simple_workflow.py --basic
# Calls: Steps 1-2 + basic CSV creation
# Output: 5-column CSV with person data only
```

### **Text Extraction with Progress Tracking**
```bash
python simple_workflow.py --text --batch-size 5 --resume
# Calls: All steps + text extraction + progress management
# Output: CSV with document text + progress files
```

### **Stream Missing Media Files**
```bash
python core/process_pending_metadata_downloads.py
# Calls: S3 streaming pipeline for metadata gaps
# Output: Media files in S3 + updated CSV mappings
```

### **Fix File Extensions**
```bash
python core/fix_s3_extensions.py
# Calls: S3 extension correction pipeline
# Output: Properly typed media files in S3
```

---

## ğŸ¯ CRITICAL SUCCESS PATH

For the complete pipeline to succeed, this exact execution order is required:

1. **Configuration Loading** (`utils/config.py::get_config()`)
2. **Sheet Download** (`step1_download_sheet()`)
3. **Data Extraction** (`step2_extract_people_and_docs()`)
4. **Document Processing** (`step3_scrape_doc_contents()` + `step4_extract_links()`)
5. **Record Creation** (`step5_process_extracted_data()`)
6. **CSV Generation** (`step6_map_data()`)
7. **S3 Integration** (streaming components as needed)

Any interruption in this chain will result in incomplete data processing, but the modular design allows for resumable operations through progress tracking.

---

## ğŸ”§ MAINTENANCE & DEBUGGING

### **Key Log Locations**
- `logs/runs/[TIMESTAMP]/main.log` â†’ Primary execution log
- `logs/runs/[TIMESTAMP]/errors.log` â†’ Error details
- `data/extraction_progress.json` â†’ Text extraction progress
- S3 upload reports â†’ Streaming operation results

### **Common Debug Points**
- **Configuration Issues**: Check `config/config.yaml` loading
- **Google Sheets Access**: Verify URL and permissions
- **Selenium Failures**: Check WebDriver setup and cleanup
- **S3 Access**: Validate AWS credentials and bucket permissions
- **CSV Corruption**: Review file locking and backup strategies

This complete execution map provides the foundation for understanding, debugging, and maintaining the entire typing clients ingestion pipeline.